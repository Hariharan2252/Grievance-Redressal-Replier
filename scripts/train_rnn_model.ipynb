{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06183932",
   "metadata": {},
   "source": [
    "# RNN Training Script for Grievance Redressal Replier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec19ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/grievances.csv')  # Adjust path if needed\n",
    "\n",
    "# Confirm column names\n",
    "print(\"Columns:\", df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7039b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use correct column names here\n",
    "grievances = df['grievance']\n",
    "responses = df['response']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5311ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize grievances\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(grievances)\n",
    "X = tokenizer.texts_to_sequences(grievances)\n",
    "\n",
    "# Pad sequences\n",
    "max_len = max(len(x) for x in X)\n",
    "X_padded = pad_sequences(X, maxlen=max_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49592496",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize responses (as labels)\n",
    "response_tokenizer = Tokenizer()\n",
    "response_tokenizer.fit_on_texts(responses)\n",
    "y = response_tokenizer.texts_to_sequences(responses)\n",
    "\n",
    "# Use only the first token as a class index (simplified)\n",
    "y = np.array([i[0] if len(i) > 0 else 0 for i in y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a5a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc7668",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build RNN model\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "output_classes = max(y) + 1\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=64, input_length=max_len),\n",
    "    SimpleRNN(64, return_sequences=False),\n",
    "    Dense(output_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5482016",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ce5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save model\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "model.save('../models/grievance_rnn.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a991c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save tokenizers for later use\n",
    "import pickle\n",
    "with open('../models/input_tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "with open('../models/response_tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(response_tokenizer, f)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
